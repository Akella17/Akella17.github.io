<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.55.6" />
  <meta name="author" content="Akella Ravi Tej">
  <meta name="description" content="&lt;first_name&gt;@cs.toronto.edu">

  <link rel="stylesheet" href="/css/highlight.min.css">
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <link rel="stylesheet" href="/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/academicons.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  

  <link rel="alternate" href="https://akella17.github.io/index.xml" type="application/rss+xml" title="Akella Ravi Tej">
  <link rel="feed" href="https://akella17.github.io/index.xml" type="application/rss+xml" title="Akella Ravi Tej">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://akella17.github.io/blog/Deep-Bayesian-Quadrature-Policy-Optimization/">

  

  <title>Deep Bayesian Quadrature Policy Optimization | Akella Ravi Tej</title>

</head>
<body id="top">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Akella Ravi Tej</a>
    </div>

    
    <div class="collapse navbar-collapse" id="#navbar-collapse-1">

      
      <ul class="nav navbar-nav navbar-right">
        
        <li class="nav-item"><a href="/#">Home</a></li>
        
        <li class="nav-item"><a href="/#publications">Publications</a></li>
        
        <li class="nav-item"><a href="/#Blogs">Blogs</a></li>
        
        <li class="nav-item"><a href="/#News">News</a></li>
        
      </ul>

    </div>
  </div>
</nav>

<div class="container">

<div class="pub" itemscope itemtype="http://schema.org/CreativeWork">
    <div class="pub-title">
      <img src="/img/projects/DBQPG/header.png" class="pub-banner" itemprop="image" width='100%'>

      <h1 itemprop="name" style="text-align: center">Deep Bayesian Quadrature Policy Optimization</h1>

      <p class="pub-authors" itemprop="author" align="center">
        
        <b>Akella Ravi Tej</b>, <a href="https://www.cs.purdue.edu/homes/kamyar/">Kamyar Azizzadenesheli</a>, <a href="https://mohammadghavamzadeh.github.io/">Mohammad Ghavamzadeh</a>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>
        
</p><br>
</div>

    
    <img src="/img/projects/DBQPG/DBQPG.png" class="pub-banner" itemprop="image">
    

    <h3>Abstract</h3>
    <p class="pub-abstract" itemprop="text">We study the problem of obtaining accurate policy gradient estimates using a finite number of samples. Monte-Carlo methods have been the default choice for policy gradient estimation, despite suffering from high variance in the gradient estimates. On the other hand, more sample efficient alternatives like Bayesian quadrature methods are less scalable due to their high computational complexity. In this work, we propose deep Bayesian quadrature policy gradient (DBQPG), a computationally efficient high-dimensional generalization of Bayesian quadrature, for policy gradient estimation. We show that DBQPG can substitute Monte-Carlo estimation in policy gradient methods, and demonstrate its effectiveness on a set of continuous control benchmarks. In comparison to Monte-Carlo estimation, DBQPG provides (i) more accurate gradient estimates with a significantly lower variance, (ii) a consistent improvement in the sample complexity and average return for several deep policy gradient algorithms, and, (iii) the uncertainty in gradient estimation that can be incorporated to further improve the performance.</p>

    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Publication</div>
          <div class="col-xs-12 col-sm-9"><a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a></div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Date</div>
          <div class="col-xs-12 col-sm-9" itemprop="datePublished">
            Jun, 2020
          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="row" style="padding-top: 10px">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading" style="line-height:34px;">Links</div>
          <div class="col-xs-12 col-sm-9">

            
<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/pdf/2006.15637.pdf">
  PDF
</a>
      
      
<a class="btn btn-primary btn-outline btn-xs"
onclick="
    var div = document.getElementById('DBQPG_bib');
    if (div.style.display !== 'none') {
        div.style.display = 'none';
    }
    else {
        div.style.display = 'block';
    }
">
  BibTeX
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://akella17.github.io/blogs/Bayesian-Quadrature-for-Policy-Gradient/">
  Blog
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://akella17.github.io/publications/Deep-Bayesian-Quadrature-Policy-Optimization/DBQPG_Slides.pdf">
  Slides
</a>

<a class="btn btn-primary btn-outline btn-xs" href="https://github.com/Akella17/Deep-Bayesian-Quadrature-Policy-Optimization">
  Code
</a>
      
      
<pre id = "DBQPG_bib", style="display:none">
@article{ravi2020DBQPG,
title={Deep Bayesian Quadrature Policy Optimization},
author={Akella Ravi Tej and Kamyar Azizzadenesheli and Mohammad Ghavamzadeh and Anima Anandkumar and Yisong Yue},
journal={arXiv preprint arXiv:2006.15637},
year={2020}
}
</pre>



          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="space-below"></div>

    <div class="article-style">

<h2>TL;DR</h2>
<ul>
  <li>We propose a new policy gradient estimator, <strong>deep Bayesian quadrature policy gradient (DBQPG)</strong>, as an alternative to the predominantly used Monte-Carlo estimator. DBQPG provides <strong>more accurate</strong> gradient estimates with a significantly <strong>lower variance</strong>, quantifies the <strong>uncertainty</strong> in policy gradient estimation, and consistently offers a <strong>better performance</strong> for 3 policy gradient algorithms and across 7 MuJoCo environments.</li>
  <li>We also propose a new policy gradient method, <strong>uncertainty aware policy gradient (UAPG)</strong>, that utilizes the quantified estimation uncertainty in DBQPG to compute <strong>reliable policy updates</strong> with <strong>robust step-sizes</strong>.</li>
</ul>

<h3><b>Quality of Gradient Estimation</b></h3>

<p><strong>1. Accuracy Plot (Gradient Cosine Similarity) :-</strong>
<img src="/img/projects/DBQPG/accuracy_plot.png" alt="Accuracy_Plot"/></p>

<p><strong>2. Variance Plot (Normalized Gradient Variance) :-</strong>
<img src="/img/projects/DBQPG/variance_plot.png" alt="Variance_Plot"/></p>

<h3 id="b-qualitative-results-b"><b>MuJoCo Experiments</b></h3>

<p><strong>1. Vanilla Policy Gradient :-</strong>
<img src="/img/projects/DBQPG/VanillaPG_plot.png" alt="VanillaPG_Plot"/></p>

<p><strong>2. Natural Policy Gradient :-</strong>
<img src="/img/projects/DBQPG/NPG_plot.png" alt="NPG_Plot"/></p>
      
<p><strong>3. Trust Region Policy Optimization :-</strong>
<img src="/img/projects/DBQPG/TRPO_plot.png" alt="TRPO_Plot"/></p>
</div>

  </div>


</div>
<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2020 Akella Ravi Tej &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.4/TweenMax.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/gsap/latest/plugins/ScrollToPlugin.min.js"></script>
    <script src="/js/jquery-1.12.3.min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/hugo-academic.js"></script>
    

    
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-53775284-5', 'auto');
        ga('send', 'pageview');

         
        var links = document.querySelectorAll('a');
        Array.prototype.map.call(links, function(item) {
            if (item.host != document.location.host) {
                item.addEventListener('click', function() {
                    var action = item.getAttribute('data-action') || 'follow';
                    ga('send', 'event', 'outbound', action, item.href);
                });
            }
        });
    </script>
    

    
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    <script async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML"></script>
    

  </body>
</html>

